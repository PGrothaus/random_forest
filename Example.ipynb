{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the Titanic Kaggle competition to test out our implementation of the decision tree. The script below trains a tree that achieves 78.9% of classification accuracy on the competition, which is a decent improvement on the gender-model (predicting that all men die and all women survive).\n",
    "\n",
    "In this competition we try to build a model that can correctly predict which pasengers survived the Titanic accident. Accuracy is hence the metric we try to optimise on.\n",
    "\n",
    "As a hyperparameter we need to chose the depth of the tree. We thus take 25% of the training data aside as validation set and use the precision on the validation set to set the depth of the tree. After we found this depth, we train the whole tree on the complete training data and see what the accuracy on the test data is (by submitting to kaggle).\n",
    "Any further hyper parameter optimisation is beyond the scope of this example (e.g. minimum examples in each leaf).\n",
    "\n",
    "This implementation of the decision tree is using Information gain as a splitting criterion. At each node, we check all features and chose the feature and split-value that maximise the information gain.\n",
    "See, e.g.: http://chem-eng.utoronto.ca/~datamining/dmc/decision_tree.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from rforest import DecisionTree\n",
    "import data_preparation as dataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a couple of parameters and fix the random seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train = 0.75  # Fraction of data used as training data\n",
    "N_ftr = 9  # number of features in the dataset\n",
    "depths = range(2,10)  # list of different tree depths (need to find best hyperparameter here)\n",
    "Nlabel = 2  # number of target values (dead and alive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and split it into train and validation set. Our training data is a list here. The first list item contains training examples of people that died, the second list item of people that survived. This choice helps us in the tree to calculate the information gain, but is specific to this implementation and not compatible with libraries, such as sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataPrep.titanic('train.csv', LABELED=True)\n",
    "N0 = int(r_train * np.asarray(data[0]).shape[0])\n",
    "N1 = int(r_train * np.asarray(data[1]).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 10) (256, 10)\n"
     ]
    }
   ],
   "source": [
    "trainData  = [data[0][:N0, :], data[1][:N1, :]]\n",
    "print np.asarray(trainData[0]).shape, np.asarray(trainData[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 222, 10)\n"
     ]
    }
   ],
   "source": [
    "crossValData = [np.concatenate([data[0][N0 + 1:, :], data[1][N1 + 1:, :]])]\n",
    "print np.asarray(crossValData).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a helper function that calculates the error (misclassification rate) and the accuracy. It will evaluate each tree that we build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(output):\n",
    "    n_examples = output.shape[0]\n",
    "    prediction = output[:, N_ftr]\n",
    "    target = output[:, N_ftr + 1]\n",
    "    misclass = np.where(target == prediction, 0, 1)\n",
    "    error = np.mean(misclass)\n",
    "    precision = 1. - error\n",
    "    return error, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a basic loop to find the best tree-depth.\n",
    "After the loop, we use the best depth and initialise a new tree. We then use the complete training data to train that tree.\n",
    "We use that new tree to predict the test data and create a submit file for the Kaggle webpage.\n",
    "We will find that the best depth is 4.\n",
    "We will also see that the deeper the tree, the better the accuracy on the training data. This shows that our implementation is working as it can overfit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "error and accuracy on training set: 0.211, 0.789\n",
      "error and accuracy on validation set: 0.22, 0.78\n",
      "\n",
      "3\n",
      "error and accuracy on training set: 0.208, 0.792\n",
      "error and accuracy on validation set: 0.215, 0.785\n",
      "\n",
      "4\n",
      "error and accuracy on training set: 0.171, 0.829\n",
      "error and accuracy on validation set: 0.161, 0.839\n",
      "\n",
      "5\n",
      "error and accuracy on training set: 0.166, 0.834\n",
      "error and accuracy on validation set: 0.175, 0.825\n",
      "\n",
      "6\n",
      "error and accuracy on training set: 0.148, 0.852\n",
      "error and accuracy on validation set: 0.175, 0.825\n",
      "\n",
      "7\n",
      "error and accuracy on training set: 0.132, 0.868\n",
      "error and accuracy on validation set: 0.175, 0.825\n",
      "\n",
      "8\n",
      "error and accuracy on training set: 0.108, 0.892\n",
      "error and accuracy on validation set: 0.179, 0.821\n",
      "\n",
      "9\n",
      "error and accuracy on training set: 0.097, 0.903\n",
      "error and accuracy on validation set: 0.175, 0.825\n",
      "\n",
      "4\n",
      "(1, 418, 10)\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.\n",
    "best_depth = 0\n",
    "for depth in depths:\n",
    "    print depth\n",
    "    RF = DecisionTree(depth, N_ftr, 2)\n",
    "    RF.train([trainData])\n",
    "\n",
    "    output = RF.predict_label([np.concatenate(trainData)])\n",
    "    error, accuracy = calculate_error(output)\n",
    "    print 'error and accuracy on training set: {}, {}'.format(\n",
    "        round(error, 3), round(accuracy, 3))\n",
    "\n",
    "    output = RF.predict_label(crossValData)\n",
    "    error, accuracy = calculate_error(output)\n",
    "    print 'error and accuracy on validation set: {}, {}\\n'.format(\n",
    "        round(error, 3), round(accuracy, 3))\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_depth = depth\n",
    "\n",
    "print best_depth\n",
    "trainData  = [data[0][:, :], data[1][:, :]]\n",
    "RF = DecisionTree(best_depth, N_ftr, 2)\n",
    "RF.train([trainData])\n",
    "\n",
    "testData = dataPrep.titanic('test.csv', LABELED=False)\n",
    "print np.asarray(testData).shape\n",
    "\n",
    "output = RF.predict_label(testData)\n",
    "output = zip(output[:, N_ftr], output[:, N_ftr + 1])\n",
    "output.sort(key=lambda tup: tup[0])\n",
    "pId, survival = zip(*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submit.txt', 'w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "for ii in range(len(pId)):\n",
    "    if ii == 0:\n",
    "        continue\n",
    "    with open('submit.txt', 'a') as f:\n",
    "        f.write(str(int(pId[ii])) + ',' + str(int(survival[ii])) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we submit this file to Kaggle, we obtain an accuracy on the test set of 78.9%.\n",
    "This is an imporvement on the gender model (which predicts that all men die and all women survive) and shows that our implementation of a decision tree is working well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
